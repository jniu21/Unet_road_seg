# -*- coding: utf-8 -*-
"""model_resunet

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17G9ikRGNCdqGUkYVw3ztyzoOnUsr7rnA
"""

# -*- coding: utf-8 -*-
"""
(Modified for Vanilla U-Net)

Author: edwin.p.alegre (Modified)
"""

################################## LIBRARIES ##################################

from tensorflow.keras.layers import (Conv2D, BatchNormalization, Activation,
                                     UpSampling2D, concatenate, Lambda,
                                     MaxPooling2D)
from tensorflow.keras import Model, Input
import tensorflow as tf

################################ DOUBLE CONVOLUTIONAL BLOCK ##################################
# In vanilla U-Net, each block applies two sequential convolution layers
# with batch normalization and ReLU activation without any residual addition.

def conv_block(feature_map, filters):
    conv_1 = Conv2D(filters, kernel_size=(3, 3), padding='same')(feature_map)
    bn1 = BatchNormalization()(conv_1)
    act1 = Activation('relu')(bn1)

    conv_2 = Conv2D(filters, kernel_size=(3, 3), padding='same')(act1)
    bn2 = BatchNormalization()(conv_2)
    act2 = Activation('relu')(bn2)

    return act2

###################################### ENCODER ######################################
# The encoder now uses a double conv block followed by a pooling operation
# for downsampling. It also stores feature maps for later concatenation in the decoder.

def encoder(feature_map):
    skips = []  # To store feature maps for skip connections

    # Block 1: 64 filters
    conv1 = conv_block(feature_map, filters=64)
    skips.append(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    # Block 2: 128 filters
    conv2 = conv_block(pool1, filters=128)
    skips.append(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    # Block 3: 256 filters
    conv3 = conv_block(pool2, filters=256)
    skips.append(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    return skips, pool3

###################################### BOTTLENECK ######################################
# The bottleneck is simply another double-conv block, here with 512 filters.

def bottleneck(pool):
    return conv_block(pool, filters=512)

###################################### DECODER ######################################
# The decoder upsamples the bottleneck feature map and concatenates it with
# the corresponding feature map from the encoder. It then applies a double conv block.

def decoder(feature_map, skips):
    # Block 1: Up-sample and concatenate with the 3rd encoder block's features
    up1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(feature_map)
    concat1 = concatenate([up1, skips[2]], axis=3)
    dec1 = conv_block(concat1, filters=256)

    # Block 2: Up-sample and concatenate with the 2nd encoder block's features
    up2 = UpSampling2D(size=(2, 2), interpolation='bilinear')(dec1)
    concat2 = concatenate([up2, skips[1]], axis=3)
    dec2 = conv_block(concat2, filters=128)

    # Block 3: Up-sample and concatenate with the 1st encoder block's features
    up3 = UpSampling2D(size=(2, 2), interpolation='bilinear')(dec2)
    concat3 = concatenate([up3, skips[0]], axis=3)
    dec3 = conv_block(concat3, filters=64)

    return dec3

###################################### VANILLA U-NET ######################################
# The complete U-Net model combines the encoder, bottleneck, decoder and a final
# output convolution layer with sigmoid activation.

def UNet(inputshape):
    # Input layer and normalization (scaling input to 0-1)
    model_input = Input(shape=inputshape)
    model_input_norm = Lambda(lambda x: x / 255)(model_input)

    # Encoder: obtains skip connections and the final pooled output.
    skips, pool = encoder(model_input_norm)

    # Bottleneck layer.
    bn = bottleneck(pool)

    # Decoder: upsamples and concatenates using the stored skip connections.
    dec = decoder(bn, skips)

    # Output layer: 1 filter with sigmoid activation for binary segmentation.
    model_output = Conv2D(filters=1, kernel_size=(1, 1), padding='same',
                          activation='sigmoid')(dec)

    return Model(model_input, model_output)

################################ SANITY CHECK #################################
if __name__ == "__main__":
    model = UNet((224, 224, 3))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    model.summary()
    # Optionally, you can plot the model architecture
    tf.keras.utils.plot_model(model, to_file='unet_model.png', show_layer_names=True,
                               show_shapes=True, rankdir='TB')