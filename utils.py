# -*- coding: utf-8 -*-
"""utils

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FZmgzDyyMKKrxCeB-0ZVDwdd8_cd1hWh
"""

# -*- coding: utf-8 -*-
"""
Created on Sat Jun 20 02:44:43 2020

@author: edwin.p.alegre
"""
from PIL import Image
import os
import numpy as np
from skimage.io import imread
from tqdm import tqdm

OGIMG_SIZE = 1500
IMG_SIZE = 224
OVERLAP = 14

def imgstitch(img_path):
    """
    This function overlays the predicted image patches with each other to produce the final output image.
    It should be noted that the overlap regions are INTENDED to be averaged to minimize error. This is not
    done in this function. They are just overwritten by the next image patch. This will be implemented in the future
    for a more robust approach

    Parameters
    ----------
    img_path : STRING
        Path to directory with test image patches

    Returns
    -------
    None. The final stitched image will be automatically saved in the same directory as the image patches with the
    name 'ouptut.png''

    """
    _, _, img_files = next(os.walk(img_path))

    img_files = sorted(img_files,key=lambda x: int(os.path.splitext(x)[0]))
    IMG_WIDTH, IMG_HEIGHT = (Image.open(img_path + '/11.png')).size

    img = np.zeros((len(img_files), IMG_WIDTH, IMG_HEIGHT), dtype=np.uint8)
    full_img = Image.new('RGB', (1470, 1470))
    x, y = (0, 0)

    for n, id_ in enumerate(img_files):
        img = Image.open(img_path + '/' + str(id_))
        if x < 1460:
            full_img.paste(img, (x, y))
            x += IMG_WIDTH - OVERLAP
        if x > 1460:
            x = 0
            y += IMG_WIDTH - OVERLAP
            full_img.paste(img, (x, y))

    full_img.save(os.path.join(img_path, 'output') + '.png', 'PNG')

def DatasetLoad(train_dataset, test_dataset):
    """
    Loads the training and test datasets and splits 10% of the training data
    for validation.

    Parameters
    ----------
    train_dataset : STRING
        Directory containing the training images and masks in separate folders
        named 'image' and 'mask'.
    test_dataset : STRING
        Directory containing the test patches. This directory should hold subdirectories,
        each with an 'image' and a 'mask' folder.

    Returns
    -------
    X_train : NUMPY ARRAY
        Training images of shape [NUM_TRAIN_SAMPLES, IMG_SIZE, IMG_SIZE, 3].
    Y_train : NUMPY ARRAY
        Training masks of shape [NUM_TRAIN_SAMPLES, IMG_SIZE, IMG_SIZE, 1].
    X_test : DICTIONARY
         Test images for each test folder. Each entry is a numpy array of shape
         [NUM_TEST_SAMPLES, IMG_SIZE, IMG_SIZE, 3].
    Y_test : DICTIONARY
         Test masks for each test folder. Each entry is a numpy array of shape
         [NUM_TEST_SAMPLES, IMG_SIZE, IMG_SIZE, 1].
    X_val : NUMPY ARRAY
         Validation images (10% split of training data) of shape
         [NUM_VAL_SAMPLES, IMG_SIZE, IMG_SIZE, 3].
    Y_val : NUMPY ARRAY
         Validation masks of shape [NUM_VAL_SAMPLES, IMG_SIZE, IMG_SIZE, 1].

    Note:
    -----
    It is assumed that the training images are named as "1.png", "2.png", ..., located
    in train_dataset/image/, and similarly for the masks (located in train_dataset/mask/).
    IMG_SIZE should be defined globally.
    """

    import os
    import numpy as np
    from tqdm import tqdm
    from skimage.io import imread
    import random

    ### TRAINING DATASET ###
    # List the training image files
    _, _, train_files = next(os.walk(os.path.join(train_dataset, 'image')))
    training_imgs = len(train_files)
    train_ids = list(range(1, training_imgs + 1))

    # Shuffle the training IDs and split 90% for training, 10% for validation.
    random.shuffle(train_ids)
    split_index = int(len(train_ids) * 0.9)
    train_ids_split = train_ids[:split_index]
    val_ids_split   = train_ids[split_index:]

    # Allocate arrays for training and validation data
    X_train = np.zeros((len(train_ids_split), IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
    Y_train = np.zeros((len(train_ids_split), IMG_SIZE, IMG_SIZE, 1), dtype=np.bool)
    X_val   = np.zeros((len(val_ids_split), IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
    Y_val   = np.zeros((len(val_ids_split), IMG_SIZE, IMG_SIZE, 1), dtype=np.bool)

    # Load training images and masks
    for n, id_ in tqdm(enumerate(train_ids_split), total=len(train_ids_split)):
        X_train[n] = imread(os.path.join(train_dataset, 'image', f"{id_}.png"))
        mask = np.zeros((IMG_SIZE, IMG_SIZE, 1), dtype=np.bool)
        # The loop below is to ensure any potential multiple masks per image are combined.
        for _ in next(os.walk(os.path.join(train_dataset, 'mask'))):
            mask_ = imread(os.path.join(train_dataset, 'mask', f"{id_}.png"))
            mask_ = np.expand_dims(mask_, axis=-1)
            mask = np.maximum(mask, mask_)
        Y_train[n] = mask

    # Load validation images and masks (using the 10% split)
    for n, id_ in tqdm(enumerate(val_ids_split), total=len(val_ids_split)):
        X_val[n] = imread(os.path.join(train_dataset, 'image', f"{id_}.png"))
        mask = np.zeros((IMG_SIZE, IMG_SIZE, 1), dtype=np.bool)
        for _ in next(os.walk(os.path.join(train_dataset, 'mask'))):
            mask_ = imread(os.path.join(train_dataset, 'mask', f"{id_}.png"))
            mask_ = np.expand_dims(mask_, axis=-1)
            mask = np.maximum(mask, mask_)
        Y_val[n] = mask

    ### TESTING DATASET ###
    # Get list of test folders
    _, test_fol, _ = next(os.walk(test_dataset))
    # Assume all test folders have the same number of images, using the first folder to determine that number.
    _, _, test_files = next(os.walk(os.path.join(test_dataset, test_fol[0], 'image')))
    test_imgs = len(test_files)
    test_ids = list(range(1, test_imgs + 1))

    X_test = {}
    Y_test = {}

    # Create arrays for each test folder
    for folder in test_fol:
        X_test[folder] = np.zeros((len(test_ids), IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
        Y_test[folder] = np.zeros((len(test_ids), IMG_SIZE, IMG_SIZE, 1), dtype=np.bool)

    # Load testing images and masks for each folder
    for folder in test_fol:
        test_path = os.path.join(test_dataset, folder)
        for n, id_ in tqdm(enumerate(test_files), total=len(test_files)):
            X_test[folder][n] = imread(os.path.join(test_path, 'image', f"{id_}"))
            mask = np.zeros((IMG_SIZE, IMG_SIZE, 1), dtype=np.bool)
            for _ in next(os.walk(os.path.join(test_path, 'mask'))):
                mask_ = imread(os.path.join(test_path, 'mask', f"{id_}"))
                mask_ = np.expand_dims(mask_, axis=-1)
                mask = np.maximum(mask, mask_)
            Y_test[folder][n] = mask

    return X_train, Y_train, X_test, Y_test, X_val, Y_val